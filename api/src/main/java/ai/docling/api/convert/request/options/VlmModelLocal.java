package ai.docling.api.convert.request.options;

import java.util.Collections;
import java.util.HashMap;
import java.util.Map;

import org.jspecify.annotations.Nullable;

import com.fasterxml.jackson.annotation.JsonInclude;
import com.fasterxml.jackson.annotation.JsonProperty;

/**
 * Options for running a local vision-language model for the VLM pipeline.
 * The parameters refer to a model hosted on Hugging Face.
 */
@JsonInclude(JsonInclude.Include.NON_NULL)
public class VlmModelLocal {
    @JsonProperty("repo_id")
    private String repoId;

    @JsonProperty("prompt")
    private String prompt;

    @JsonProperty("scale")
    private Integer scale;

    @JsonProperty("response_format")
    private ResponseFormat responseFormat;

    @JsonProperty("inference_framework")
    private InferenceFramework inferenceFramework;

    @JsonProperty("transformers_model_type")
    private TransformersModelType transformersModelType;

    @JsonProperty("extra_generation_config")
    private Map<String, Object> extraGenerationConfig = new HashMap<>();

    /**
     * Gets the repository id from the Hugging Face Hub.
     *
     * @return the repository id
     */
    @Nullable
    public String getRepoId() {
        return repoId;
    }

    /**
     * Sets the repository id from the Hugging Face Hub.
     *
     * @param repoId the repository id
     */
    public void setRepoId(@Nullable String repoId) {
        this.repoId = repoId;
    }

    /**
     * Sets the repository id from the Hugging Face Hub.
     *
     * @param repoId the repository id
     * @return this instance for method chaining
     */
    public VlmModelLocal withRepoId(@Nullable String repoId) {
        setRepoId(repoId);
        return this;
    }

    /**
     * Gets the prompt used when calling the vision-language model.
     *
     * @return the prompt
     */
    @Nullable
    public String getPrompt() {
        return prompt;
    }

    /**
     * Sets the prompt used when calling the vision-language model.
     *
     * @param prompt the prompt
     */
    public void setPrompt(@Nullable String prompt) {
        this.prompt = prompt;
    }

    /**
     * Sets the prompt used when calling the vision-language model.
     *
     * @param prompt the prompt
     * @return this instance for method chaining
     */
    public VlmModelLocal withPrompt(@Nullable String prompt) {
        setPrompt(prompt);
        return this;
    }

    /**
     * Gets the scale factor of the images used.
     *
     * @return the scale factor
     */
    @Nullable
    public Integer getScale() {
        return scale;
    }

    /**
     * Sets the scale factor of the images used.
     *
     * @param scale the scale factor
     */
    public void setScale(@Nullable Integer scale) {
        this.scale = scale;
    }

    /**
     * Sets the scale factor of the images used.
     *
     * @param scale the scale factor
     * @return this instance for method chaining
     */
    public VlmModelLocal withScale(@Nullable Integer scale) {
        setScale(scale);
        return this;
    }

    /**
     * Gets the type of response generated by the model.
     *
     * @return the response format
     */
    @Nullable
    public ResponseFormat getResponseFormat() {
        return responseFormat;
    }

    /**
     * Sets the type of response generated by the model.
     *
     * @param responseFormat the response format
     */
    public void setResponseFormat(@Nullable ResponseFormat responseFormat) {
        this.responseFormat = responseFormat;
    }

    /**
     * Sets the type of response generated by the model.
     *
     * @param responseFormat the response format
     * @return this instance for method chaining
     */
    public VlmModelLocal withResponseFormat(@Nullable ResponseFormat responseFormat) {
        setResponseFormat(responseFormat);
        return this;
    }

    /**
     * Gets the inference framework to use.
     *
     * @return the inference framework
     */
    @Nullable
    public InferenceFramework getInferenceFramework() {
        return inferenceFramework;
    }

    /**
     * Sets the inference framework to use.
     *
     * @param inferenceFramework the inference framework
     */
    public void setInferenceFramework(@Nullable InferenceFramework inferenceFramework) {
        this.inferenceFramework = inferenceFramework;
    }

    /**
     * Sets the inference framework to use.
     *
     * @param inferenceFramework the inference framework
     * @return this instance for method chaining
     */
    public VlmModelLocal withInferenceFramework(@Nullable InferenceFramework inferenceFramework) {
        setInferenceFramework(inferenceFramework);
        return this;
    }

    /**
     * Gets the type of transformers auto-model to use.
     *
     * @return the transformers model type
     */
    @Nullable
    public TransformersModelType getTransformersModelType() {
        return transformersModelType;
    }

    /**
     * Sets the type of transformers auto-model to use.
     *
     * @param transformersModelType the transformers model type
     */
    public void setTransformersModelType(@Nullable TransformersModelType transformersModelType) {
        this.transformersModelType = transformersModelType;
    }

    /**
     * Sets the type of transformers auto-model to use.
     *
     * @param transformersModelType the transformers model type
     * @return this instance for method chaining
     */
    public VlmModelLocal withTransformersModelType(@Nullable TransformersModelType transformersModelType) {
        setTransformersModelType(transformersModelType);
        return this;
    }

    /**
     * Gets the extra generation config from Hugging Face.
     *
     * @return the extra generation config
     * @see <a href="https://huggingface.co/docs/transformers/en/main_classes/text_generation#transformers.GenerationConfig">Hugging Face GenerationConfig</a>
     */
    @Nullable
    public Map<String, Object> getExtraGenerationConfig() {
        return Collections.unmodifiableMap(extraGenerationConfig);
    }

    /**
     * Sets the extra generation config from Hugging Face.
     *
     * @param extraGenerationConfig the extra generation config
     * @see <a href="https://huggingface.co/docs/transformers/en/main_classes/text_generation#transformers.GenerationConfig">Hugging Face GenerationConfig</a>
     */
    public void setExtraGenerationConfig(@Nullable Map<String, Object> extraGenerationConfig) {
      this.extraGenerationConfig.clear();

      if (extraGenerationConfig != null) {
        this.extraGenerationConfig.putAll(extraGenerationConfig);
      }
    }

    /**
     * Sets the extra generation config from Hugging Face.
     *
     * @param extraGenerationConfig the extra generation config
     * @return this instance for method chaining
     * @see <a href="https://huggingface.co/docs/transformers/en/main_classes/text_generation#transformers.GenerationConfig">Hugging Face GenerationConfig</a>
     */
    public VlmModelLocal withExtraGenerationConfig(@Nullable Map<String, Object> extraGenerationConfig) {
        setExtraGenerationConfig(extraGenerationConfig);
        return this;
    }

    @Override
    public String toString() {
        return "VlmModelLocal{" +
                "repoId='" + repoId + '\'' +
                ", prompt='" + prompt + '\'' +
                ", scale=" + scale +
                ", responseFormat=" + responseFormat +
                ", inferenceFramework=" + inferenceFramework +
                ", transformersModelType=" + transformersModelType +
                ", extraGenerationConfig=" + extraGenerationConfig +
                '}';
    }

    /**
     * Inference framework to use.
     */
    public enum InferenceFramework {

        @JsonProperty("mlx") MLX,
        @JsonProperty("transformers") TRANSFORMERS,
        @JsonProperty("vllm") VLLM

    }

    /**
     * Type of transformers auto-model to use.
     */
    public enum TransformersModelType {

        @JsonProperty("automodel") AUTOMODEL,
        @JsonProperty("automodel-vision2seq") AUTOMODEL_VISION2SEQ,
        @JsonProperty("automodel-causallm") AUTOMODEL_CAUSALLM,
        @JsonProperty("automodel-imagetexttotext") AUTOMODEL_IMAGETEXTTOTEXT

    }

}
